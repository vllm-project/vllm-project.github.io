---
layout: post
title: "Announcing vllm.ai Website"
author: "vLLM Team"
image: /assets/figures/2025-11-30-vllm-omni/vllm-omni-logo-text-dark.png
---

For a long time, [vllm.ai](https://vllm.ai) simply redirected to the [vLLM GitHub page](https://github.com/vllm-project/vllm). Thanks to the community, we now have a brand-new [vllm.ai](https://vllm.ai) website, drawing inspiration from [PyTorch website](https://pytorch.org).

<p align="center">  
<img src="/assets/figures/2025-12-12-vllm-ai-website/homepage.jpg" alt="vllm-ai website" width="80%">  
</p>

The new website features an installation selector to guide users in installing vLLM across various environments.

<p align="center">  
<img src="/assets/figures/2025-12-12-vllm-ai-website/install.jpg" alt="vllm-ai website" width="80%">  
</p>

## Why a New Website?

The motivation behind this change is clear: we need to separate the maintenance of community events and logistics updates from the GitHub project. Previously, almost all information about vLLM was hosted on GitHub, with event announcements and meetup slides added through pull requests. This process placed an unnecessary burden on developers who wanted to focus on code development.

Going forward, we will move most community events and logistics updates from the GitHub project to the vLLM website, allowing the GitHub project to focus more on code development.

One potential drawback is that people can no longer submit pull requests to request changes as they currently do. To address this, we've created **website-feedback@vllm.ai**. If you have any suggestions to improve the website, please send an email to this address, and we will review and update accordingly.

## New Community Communication Channels

In addition to the new website, we've added several new email addresses for community communication:

* **talentpool@vllm.ai** - Submit your resume for internships and full-time positions. We will forward resumes to our partner companies to give you more exposure. LLM inference is in high demand, and our partner companies are eager to hire talented engineers.
* **collaboration@vllm.ai** - For partner companies interested in accessing resumes, organizing meetups, or technical partnerships. We are open to collaborating with any company interested in using vLLM in their products or services. This will gradually replace the existing functionality of vllm-questions@lists.berkeley.edu.
* **social-promotion@vllm.ai** - For social media promotion collaborations (Twitter/X, LinkedIn, Reddit). If you have anything interesting to share about vLLM, please send an email to this address, and we will review and promote it.

From a research project to a widely used production inference engine, vLLM would not be where it is today without the incredible support from our community. We're excited to continue building the future of LLM inference together!
